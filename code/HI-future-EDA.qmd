---
jupyter: python3
---

```{python}
import numpy as np
import matplotlib.pyplot as plt
import geopandas as gpd
import pandas as pd
import glob
import os
import rasterio
import xarray as xr
import scipy
import re
```

```{python}
models = ["SMHI-RCA", "MPICSC-REMO1", "DMI-HIRHAM"]
variants = ["RCP85", "RCP45", "RCP26"]
variables = ["tas", "tasmax"]
years = range(2031, 2041)

models_dict = {model: {variant: glob.glob("../data/prognosedaten/*"+"_"+"*"+model+"*"+variant+"*"+".nc") for variant in variants} for model in models}
models_dict2 = {model: {variant: {re.split("_",os.path.basename(filename))[0]:os.path.basename(filename)  for filename in filenames} for variant, filenames in variant.items()} for model, variant in models_dict.items()}
```

```{python}
models_dict

```

```{python}
ds = xr.open_mfdataset(models_dict["MPICSC-REMO1"]["RCP85"])

ds
```

```{python}
# boilerplate
# [[filenames for variant, filenames in variant.items()] for model, variant in models_dict.items()]
```

```{python}
prognosis_all = {model: {variant: xr.open_mfdataset(filenames) for variant, filenames in variant.items()} for model, variant in models_dict.items()}
```

```{python}
# what dimensions does the netCDF file have?
ds.dims

# the shape of lon 220 cells (each 2km) east-west, looks correct
# the shape of lat 101 cells (each 2km) north-south, looks correct
# the shape of time 43'434 days, ~118 days (1981-2099) looks correct
```

```{python}
# What variables does the dataset have?
ds.coords
```

```{python}
# sadly, not many attributes attached to the dataset
for key, val in ds.attrs.items():
    print(key, val, "\n")
```

```{python}
# I can extract a specific range like so:
ds.sel(time = slice("2031-04-01", "2031-09-30"))
```

```{python}
# debugging
minx=7.810030844025151
miny=46.757013088082914
maxx=8.540348762846177
maxy=47.305180036206615
for variant in variants:
    prognosis_all[models[0]][variant].sel(time = slice("2031-04-01", "2031-09-30"), lon = slice(minx, maxx), lat = slice(miny, maxy)).tas.resample(time = "W").mean().mean(("lon","lat")).plot(label = variant)
plt.legend()
plt.title(models[0])

#plt.savefig("../plots/"+models[0]+".tif")
```

```{python}
# debugging
model = models[0]

for variant in variants:
    xr.concat([prognosis_all[model][variant].sel(time = slice(str(year)+"-04-01", str(year)+"-09-30"), lon = slice(minx, maxx), lat = slice(miny, maxy)) for year in years], pd.Index(years, name = "year")).tas.groupby("year").mean(...).plot(label = variant)
plt.legend()
plt.title(model)
```

```{python}
# debugging
def mean_summmer_temp(x, var, model, variant, years = range(2031, 2041),minx=7.810030844025151, miny=46.757013088082914,maxx=8.540348762846177, maxy=47.305180036206615):
    return xr.concat([x[model][variant][var].sel(time = slice(str(year)+"-04-01", str(year)+"-09-30"), lon = slice(minx, maxx), lat = slice(miny, maxy)) for year in years], pd.Index(years, name = "year")).groupby("year").mean(...)
    


mean_summer_temp_vals = xr.concat([xr.concat([mean_summmer_temp(prognosis_all, "tas",model, variant) for model in models], pd.Index(models, name = "models")) for variant in variants], pd.Index(variants, name = "variants"))
```

```{python}
mean_summer_temp_vals
```

```{python}
# debugging
mean_summer_temp_vals.plot.line(x = "year", col = "models")
#plt.title("Yearly mean of mean daily temperature during the summer\nmonths (1.4-30.9) for the years "+pretty_range(years))

plt.savefig("../output/plots/mean_daily_temp_year.pdf")
```

```{python}
models_df = pd.concat([pd.DataFrame.from_dict(models_dict2[model]).reset_index().assign(model = model) for model in models])

models_df = models_df.melt(["model","index"]).rename(columns = {"value":"filename", "variable": "variant", "index":"variable"}).sort_values(["model","variant"])

models_df = models_df[['model', 'variant', 'variable','filename']]

models_df.to_csv("../output/models-filenames.csv", index = False)
```

```{python}
# debugging
# warning, takes a long time
#mean_summer_temp_df = {'minx': 7.810030844025151,
# 'miny': 46.757013088082914,
# 'maxx': 8.540348762846177,
# 'maxy': 47.305180036206615}.to_pandas()
```

```{python}
mean_summer_temp_df = mean_summer_temp_vals.mean("year").to_pandas()
```

```{python}
# debugging
def pretty_range(x, sep = "-"):
    li = [y for y in x]
    return str(min(li))+sep+str(max(li))

mean_summer_temp_df.sort_index().plot()

plt.title("Mean of mean daily temperature during the summer\nmonths (1.4-30.9) over the years "+pretty_range(years))
    

plt.savefig("../output/plots/mean_daily_temp.pdf")
```

```{python}
def hugglin_index(x):
    return (((x.tas-10)+(x.tasmax-10))/2)*1.045

ds_hugg = (ds.sel(time = slice("2031-04-01", "2031-09-30")) # extracts a specific period from the dataset
    .groupby("time")                                        # groups the dataset by time
    .map(hugglin_index)                                     # maps the function "hugglin_index" (see above) for each day
    .sum(dim="time"))         year                              # sums up all daily values

ds_hugg = (ds_hugg
    .where(ds_hugg > 0, other = 0)                          # replaces values below 0 with 0
    .fillna(0))                                             # replaces NaN values with 0 (not tested)

plt.imshow(np.flip(ds_hugg, 0))
```

```{python}
# turn the above process into a function
def hugglin_year(x, year):
    y = x.sel(time = slice(str(year)+"-04-01", str(year)+"-09-30")).groupby("time").map(hugglin_index).sum(dim="time")
    y = y.where(y > 0, other = 0).fillna(0)
    return y

# also, create a helperfunction to plot results.
def plot(x):
    plt.imshow(np.flip(x, 0))
```

```{python}
plot(hugglin_year(ds, 2031))
```


What I need to calculate is the following (pseudocode):

```
for years in 2031-2040:
    for days in 30.09.year-01.04.(year+1):
        ((tas-10)+(tas_max-10))/2*1.045
        
```

```{python}
# Import the kanton of luzern ....
kantonsgrenze = gpd.read_file("../data/swissBOUNDARIES3D_1_3_LV95_LN02.gdb/", layer = "TLM_KANTONSGEBIET").query("NAME == 'Luzern'") # fiona.listlayers("data/swissBOUNDARIES3D_1_3_LV95_LN02.gdb/")

# buffer it with 2km, transform it to wsg84 and get the bounding box
kanton_bounds = kantonsgrenze.buffer(2000).to_crs(4326).bounds.reset_index(drop = True).to_dict()
kanton_bounds = {key: val[0] for key, val in kanton_bounds.items()}
```

```{python}
kanton_bounds
```

```{python}
# make sure that the order of the variables maches the order above
minx, miny, maxx, maxy = kanton_bounds.values()
```

Just as slicing over time, we can slice over lon / lat

```{python}
ds_hugg_lu = ds.sel(time = slice("2031-04-01", "2031-09-30"), lon = slice(minx, maxx), lat = slice(miny, maxy)).groupby("time").map(hugglin_index).sum(dim="time")
ds_hugg_lu = ds_hugg_lu.where(ds_hugg_lu>0, other = 0)
plot(ds_hugg_lu)
```

```{python}
def hugglin_bbox(x, year, minx, maxx, miny, maxy):
    y = x.sel(lon = slice(minx, maxx), lat = slice(miny, maxy))
    y = hugglin_year(y, year)
    y.name = str(year)
    return y

plot(hugglin_bbox(ds, 2031, minx, maxx, miny, maxy))
```

```{python}
def hugglin_variants(filenames, variant):
    ds = xr.open_mfdataset(filenames)
    ds_hugg = xr.concat([hugglin_bbox(ds, year, minx, maxx, miny, maxy) for year in years], "year").mean(dim = "year")
    ds_hugg.name = variant
    return ds_hugg

# this is almost exactly the same as hugglin_variants, see if you can replace it
def open_and_name(filenames, name):
    ds = xr.open_mfdataset(filenames)
    ds.name = name
    return ds

def my_concat(x, dimname, newname = ""):
    y = xr.concat(x, dim = pd.Index([y.name for y in x], name = dimname))
    if newname != "":
        y.name = newname
    return y

def my_open_mfdataset(x):
    return [xr.open_dataarray(y) for y in x]
```

```{python}
open_mf
```


```{python}
huggin_prognosis_list = [my_concat([hugglin_variants(filenames, variant) for variant, filenames in variants.items()], "variant", model) for model, variants in models_dict.items()]

huggin_prognosis = my_concat(huggin_prognosis_list, "model","prognosis")
```

```{python}
%%timeit -n 1 -r 1
#huggin_prognosis.variant.values.tolist()
huggin_prognosis.sel(model = "SMHI-RCA", variant = "RCP85").mean(...).values
```

```{python}
#%%timeit -n 1 -r 1

def select_model(x, model):
    y = x.sel(model = model)
    y.name = model
    return y
    

hugglin_means = concat([select_model(huggin_prognosis, model).groupby("variant").mean(...) for model in huggin_prognosis.model.values.tolist()], "model","means")
```

```{python}
hugglin_means
```

```{python}
import statistics

max([1,2])
```


the above dict comprehension replaces the following loop: 
``` 
for model_name in models_dict.keys():
    for variant_name in models_dict[model_name]:
        print("... starting with variant: ",variant_name)
        nc_files = models_dict[model_name][variant_name]
        ds = xr.open_mfdataset(nc_files)
              
        ds_hugg = xr.concat([hugglin3(ds, year, minx, maxx, miny, maxy) for year in range(2031, 2041)], "year").mean(dim = "year")
        ds_hugg.name = variant_name
        #ds_hugg.rio.write_crs("EPSG:4326", inplace=True)
        #ds_hugg_2056 = ds_hugg.rio.reproject("EPSG:2056")
            
        subdir = "../output2/pronosis/"
        os.makedirs(subdir, exist_ok=True)

        ds_hugg.rio.to_raster(subdir+model_name+"_"+variant_name+".tif")
        
```

```{python}
#xr.merge([mega["SMHI-RCA"], mega["MPICSC-REMO1"]])
mega
```

```{python}
model_outputs = {model: {variant: glob.glob("../output2/pronosis/"+model+"_"+variant+"*.tif") for variant in variants} for model in models}

def get_mean(x):
    return xr.open_dataset(x[0]).to_array().mean().values.item()
```

these next lines need to be adapted to the fact that now each model has a xarray.Dataset consisting of the different variants (as Attributes). But maybe, the variablbes should not be attributes but its own dimension?

```{python}
mean_vals = {model: {variant: get_mean(filename) for variant, filename in variants.items()} for model, variants in model_outputs.items()}
```

```{python}
pd.DataFrame(mean_vals).sort_index().T.plot(kind = "bar", legend = False)
```

```{python}

smhi_rca = xr.concat([xr.open_dataset(x) for x in model_outputs["SMHI-RCA"]], "variant")

[xr.open_dataset(model).to_array().mean().values for model in model_outputs["SMHI-RCA"]]


#df[0].mean(keep_attrs = None)["band_data"]
```

